{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Esta tarea fue realizada en equipo por Betsy Torres y Mariana Briones\n",
    "\n",
    "# Tarea 3.1\n",
    "    \n",
    "Compre una acción inicial que no pague dividendos y estime los resultados esperados usando la Teoría de las finanzas corporativas del factor X estocástico. Asuma una distribución normal. \n",
    "- Método analítico \n",
    "- Simule en python para probar la precisión."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Importar librerias"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "import scipy.stats as st\n",
    "import pandas as pd\n",
    "pd.core.common.is_list_like = pd.api.types.is_list_like\n",
    "#import warnings\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Funciones para ajustar distribuciones"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def best_fit_distribution(data, bins=200, ax=None):\n",
    "    \"\"\"Model data by finding best fit distribution to data\"\"\"\n",
    "    # Get histogram of original data\n",
    "    y, x = np.histogram(data, bins=bins, density=True)\n",
    "    x = (x + np.roll(x, -1))[:-1] / 2.0\n",
    "\n",
    "  # Distributions to check\n",
    "    DISTRIBUTIONS = [        \n",
    "        st.gennorm,st.genexpon,st.lognorm,st.lomax,st.maxwell,st.mielke,st.nakagami,st.ncx2,st.ncf,\n",
    "        st.nct,st.norm,st.powerlognorm, st.uniform\n",
    "    ]\n",
    "\n",
    "    # Best holders\n",
    "    best_distribution = st.norm\n",
    "    best_params = (0.0, 1.0)\n",
    "    best_sse = np.inf\n",
    "\n",
    "    # Estimate distribution parameters from data\n",
    "    for distribution in DISTRIBUTIONS:\n",
    "\n",
    "        # Try to fit the distribution\n",
    "        try:\n",
    "            # Ignore warnings from data that can't be fit\n",
    "            with warnings.catch_warnings():\n",
    "                warnings.filterwarnings('ignore')\n",
    "\n",
    "                # fit dist to data\n",
    "                params = distribution.fit(data)\n",
    "\n",
    "                # Separate parts of parameters\n",
    "                arg = params[:-2]\n",
    "                loc = params[-2]\n",
    "                scale = params[-1]\n",
    "\n",
    "                # Calculate fitted PDF and error with fit in distribution\n",
    "                pdf = distribution.pdf(x, loc=loc, scale=scale, *arg)\n",
    "                sse = np.sum(np.power(y - pdf, 2.0))\n",
    "\n",
    "                # if axis pass in add to plot\n",
    "                try:\n",
    "                    if ax:\n",
    "                        pd.Series(pdf, x).plot(ax=ax)\n",
    "                \n",
    "                except Exception:\n",
    "                    pass\n",
    "\n",
    "                # identify if this distribution is better\n",
    "                if best_sse > sse > 0:\n",
    "                    best_distribution = distribution\n",
    "                    best_params = params\n",
    "                    best_sse = sse\n",
    "\n",
    "        except Exception:\n",
    "            pass\n",
    "\n",
    "    return (best_distribution.name, best_params)\n",
    "\n",
    "def make_pdf(dist, params, size=10000):\n",
    "    \"\"\"Generate distributions's Probability Distribution Function \"\"\"\n",
    "\n",
    "    # Separate parts of parameters\n",
    "    arg = params[:-2]\n",
    "    loc = params[-2]\n",
    "    scale = params[-1]\n",
    "\n",
    "    # Get sane start and end points of distribution\n",
    "    start = dist.ppf(0.01, *arg, loc=loc, scale=scale) if arg else dist.ppf(0.01, loc=loc, scale=scale)\n",
    "    end = dist.ppf(0.99, *arg, loc=loc, scale=scale) if arg else dist.ppf(0.99, loc=loc, scale=scale)\n",
    "\n",
    "    # Build PDF and turn into pandas Series\n",
    "    x = np.linspace(start, end, size)\n",
    "    y = dist.pdf(x, loc=loc, scale=scale, *arg)\n",
    "    pdf = pd.Series(y, x)\n",
    "\n",
    "    return pdf"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Obtención de Beta y parametros de distribución normal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Beta: -0.044918330261616256\n",
      "SPOT ~ N(0.0, 15.874507866387544)\n",
      "NASDAQ ~ N(0.0, 15.874507866387544)\n",
      "\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "Raw_nas = pd.read_csv('^IXIC.csv')\n",
    "nas = Raw_nas['Adj Close']\n",
    "nas = nas[1:].values/nas[:-1].values -1\n",
    "nas = pd.DataFrame(nas,columns=['Adj Close'])\n",
    "\n",
    "Raw_sp = pd.read_csv('SPOT.csv')\n",
    "sp = Raw_sp['Adj Close']\n",
    "sp = sp[1:].values/sp[:-1].values -1\n",
    "sp = pd.DataFrame(sp,columns=['Adj Close'])\n",
    "\n",
    "Beta = nas['Adj Close'].corr(sp['Adj Close'])\n",
    "print('Beta: ' + str(Beta))\n",
    "best_fit_sp, sp_params = best_fit_distribution(sp, 200)\n",
    "print('SPOT ~ N(' + str(sp_params[0]*252) + ', ' + str(sp_params[1]*252**0.5) + ')')\n",
    "best_fit_nas, nas_params = best_fit_distribution(nas, 200)\n",
    "print('NASDAQ ~ N(' + str(nas_params[0]*252) + ', ' + str(nas_params[1]*252**0.5) + ')')\n",
    "\n",
    "print('\\n\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('norm', (0.0, 1.0))"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "best_fit_sp, sp_params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('norm', (0.0, 1.0))"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "best_fit_nas, nas_params"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Resolver analíticamente"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$ r =  \\alpha + \\beta (m - rf) + rf $$\n",
    "\n",
    "$$ E[r] = E[\\alpha + \\beta (m - rf) + rf] $$\n",
    "$$ E[r] = E[\\alpha + \\beta (m - rf) + rf] $$\n",
    "$$ E[r] = E[\\alpha] + E[\\beta (m - rf)] + E[rf] $$\n",
    "$$ E[r] = E[\\alpha] + \\beta E[m - rf] + E[rf] $$\n",
    "$$ E[r] = E[\\alpha] + \\beta E[m] - \\beta E[rf] + E[rf] $$\n",
    "$$ E[r] = E[\\alpha] + \\beta E[m] - \\beta * rf + rf $$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$ r =  \\alpha + \\beta (m - rf) + rf $$\n",
    "\n",
    "$$ Var[r] = Var [\\alpha + \\beta (m - rf) + rf] $$\n",
    "$$ Var[r] = Var[\\alpha] + Var[\\beta (m - rf)] + Var[rf] + 2 *Cov(\\alpha,m)$$\n",
    "$$ Var[r] = Var[\\alpha] + \\beta^2 Var[m - rf] + Var[rf] + 2 *Cov(\\alpha,m)$$\n",
    "$$ Var[r] = Var[\\alpha] + \\beta^2 Var[m] - \\beta^2 Var[rf] + Var[rf] + 2 *Cov(\\alpha,m)$$\n",
    "$$ Var[r] = Var[\\alpha] + \\beta^2 Var[m] - \\beta^2 * 0 + 0 + 2 *Cov(\\alpha,m)$$\n",
    "$$ Var[r] = Var[\\alpha] + \\beta^2 Var[m] + 2 *Cov(\\alpha,m)$$\n",
    "$$ Var[r] = Var[\\alpha] + \\beta^2 Var[m] + 2 * \\sqrt{Var[\\alpha]*Var[m]}*Corr[\\alpha,m]$$\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Resolver con simulación"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Alfa (spot)\n",
      "[-0.05059922]\n",
      "[16.18162989]\n",
      "m (ixic)\n",
      "[0.00481483]\n",
      "[16.03777769]\n",
      "R\n",
      "[-0.01946794]\n",
      "[16.1809358]\n",
      "Elapsed time: 8.133 sec.\n"
     ]
    }
   ],
   "source": [
    "t0 = time.time()\n",
    "n=10000\n",
    "\n",
    "rf = 0.03\n",
    "alfa = pd.DataFrame(np.random.normal(loc = sp_params[0]*252, scale = np.sqrt(sp_params[1]*np.sqrt(252)), size=n))\n",
    "alfa.columns = ['Alfa']\n",
    "\n",
    "m = pd.DataFrame(np.random.normal(loc = nas_params[0]*252, scale = np.sqrt(nas_params[1]*np.sqrt(252)), size=n))\n",
    "m.columns = ['Market']\n",
    "\n",
    "R=pd.DataFrame(np.zeros(n))\n",
    "i=0\n",
    "for i in range(n):\n",
    "    R.iloc[i,0]=alfa.iloc[i,0] + Beta*m.iloc[i,0]-Beta*rf+ rf\n",
    "\n",
    "print(\"Alfa (spot)\")\n",
    "print(alfa.mean().values)\n",
    "print(alfa.var().values)\n",
    "\n",
    "print(\"m (ixic)\")\n",
    "print(m.mean().values)\n",
    "print(m.var().values)\n",
    "\n",
    "print(\"R\")\n",
    "print(R.mean().values)\n",
    "print(R.var().values)\n",
    "\n",
    "\n",
    "t1 = time.time()\n",
    "print('Elapsed time: ' + str(np.round(t1-t0, 3)) + ' sec.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "SumZ = alfa.Alfa + m.Market\n",
    "z = pd.DataFrame(np.cov(alfa, m, rowvar=0)).iloc[0,1] #-0.8*.03+0.03\n",
    "#c = np.cov(z.T)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
